name: CI Pipeline - Fail2Ban Dashboard

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  push:
    branches: [main, develop, feature/*, fix/*]
  pull_request:
    branches: [main, develop]

env:
  FAIL2BAN_LOG_PATH: /var/tmp/fail2ban.log

jobs:
  lint:
    name: Stage 1 - Code Quality Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-ruff

      - name: Install Ruff
        run: pip install ruff

      - name: Run Ruff linter
        run: |
          ruff check api/ 
          ruff format api/ --check --diff || echo "Code needs formatting"

  build:
    name: Stage 2 - Container Build
    needs: lint
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Validate & create .env
        run: |
          if [ ! -f .env.example ]; then
            echo "ERROR: .env.example not found" && exit 1
          fi
          cp .env.example .env
          echo "FAIL2BAN_LOG_PATH=${{ env.FAIL2BAN_LOG_PATH }}" >> .env

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build API service with cache
        uses: docker/build-push-action@v5
        with:
          context: ./api
          push: false
          tags: fail2ban-api:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build remaining services
        run: docker compose build
        env:
          DOCKER_BUILDKIT: 1

  integration-tests:
    name: Stage 3 - Integration & Flow Test
    needs: build
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Create environment and mock log
        run: |
          cp .env.example .env || echo "No .env.example found, creating new .env file"
          echo "FAIL2BAN_LOG_PATH=${{ env.FAIL2BAN_LOG_PATH }}" >> .env
          echo "FAIL2BAN_LOG_PATH=${{ env.FAIL2BAN_LOG_PATH }}" >> $GITHUB_ENV
          mkdir -p "$(dirname "${{ env.FAIL2BAN_LOG_PATH}}")"
          touch "${{ env.FAIL2BAN_LOG_PATH}}"

      - name: Start service stack
        run: docker compose up -d --build

      - name: Volume diagnostics
        run: |
          echo "--- Docker Diagnostics ---"
          docker compose ps
          docker compose config | grep FAIL2BAN_LOG_PATH
          docker exec promtail ls -la ${{ env.FAIL2BAN_LOG_PATH }} || echo "Could not access the file inside promtail"
          docker exec promtail cat /etc/promtail/promtail.yaml | grep FAIL2BAN_LOG_PATH
          ls -la ${{ env.FAIL2BAN_LOG_PATH }} || echo "The file no longer exists on the host"

      - name: Docker container status
        run: |
          echo "--- Docker PS ---"
          docker ps -a
          echo "--- Docker Compose Config (resolved) ---"
          docker compose config
          echo "--- Promtail container logs (early) ---"
          docker compose logs promtail
          echo "--- API container logs (early) ---"
          docker compose logs api

      - name: Inject synthetic log line
        run: |
          TS=$(date -u '+%Y-%m-%d %H:%M:%S')
          echo "${TS},123 fail2ban.filter [5678]: INFO [sshd] Starting" > "${{ env.FAIL2BAN_LOG_PATH}}"
          echo "${TS},123 fail2ban.actions [1234]: NOTICE [sshd] Ban 80.94.95.112" >> "${{ env.FAIL2BAN_LOG_PATH}}"

      - name: Show mock log content
        run: |
          echo "--- Content of ${{ env.FAIL2BAN_LOG_PATH }} on host ---"
          cat "${{ env.FAIL2BAN_LOG_PATH }}"

      - name: Wait for API health check
        run: |
          MAX_ATTEMPTS=15
          INTERVAL=10
          for attempt in $(seq 1 $MAX_ATTEMPTS); do
            if curl --fail --silent --max-time 10 http://localhost:8000/health; then
              echo "✅ API is healthy (attempt $attempt/$MAX_ATTEMPTS)"
              break
            fi
            echo "⏳ Attempt $attempt/$MAX_ATTEMPTS failed, retrying in ${INTERVAL}s..."
            if [ $attempt -eq $MAX_ATTEMPTS ]; then
              echo "❌ API health check failed after $MAX_ATTEMPTS attempts"
              docker compose logs api
              exit 1
            fi
            sleep $INTERVAL
          done

      - name: Verify Loki service health
        run: |
          echo "🔍 Verifying Loki service..."
          for i in {1..30}; do
            if curl --fail --silent --max-time 5 http://localhost:3100/ready; then
              echo "✅ Loki is ready"
              break
            fi
            echo "⏳ Waiting for Loki... ($i/30)"
            sleep 2
          done
          echo "🧪 Testing Loki endpoints..."
          curl --fail http://localhost:3100/metrics > /dev/null || exit 1
          curl --fail http://localhost:3100/loki/api/v1/status/buildinfo > /dev/null || exit 1
          echo "✅ All Loki endpoints responding"

      - name: Check log via API
        run: |
          sleep 10
          echo "--- Checking logs in API ---"
          response=$(curl --fail "http://localhost:8000/fail2ban/logs?limit=100")
          echo "API Response:"
          echo "$response" | jq .
          echo "$response" | grep -q "80.94.95.112" || (echo "Expected IP not found in logs" && exit 1)

      - name: Display service logs
        run: docker compose logs --no-color
        if: always()

      - name: Debug on failure
        if: failure()
        run: docker compose logs

  unit-tests:
    name: Stage 4 - Unit Tests
    needs: build
    runs-on: ubuntu-latest
    outputs:
      coverage: ${{ steps.coverage.outputs.coverage }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python environment
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('api/requirements.txt') }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r api/requirements.txt
          pip install pytest pytest-asyncio pytest-cov

      - name: Set environment variables for tests
        run: |
          echo "LOKI_QUERY_URL=http://test-loki:3100/api/v1/query_range" >> $GITHUB_ENV

      - name: Run unit tests with coverage
        run: |
          cd api
          PYTHONPATH=. python -m pytest tests/ -v --tb=short --cov=. --cov-report=html --cov-report=term --cov-report=json --cov-fail-under=60
        env:
          LOKI_QUERY_URL: http://test-loki:3100/api/v1/query_range

      - name: Coverage comment
        id: coverage
        run: |
          cd api
          COVERAGE=$(python -c "import json; print(json.load(open('coverage.json'))['totals']['percent_covered_display'])")
          echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT

          # Create report for comment (in English)
          echo "### 📊 Code Coverage Report" > coverage_comment.md
          echo "" >> coverage_comment.md
          echo "**Total coverage: $COVERAGE%**" >> coverage_comment.md
          echo "" >> coverage_comment.md

          if (( $(echo "$COVERAGE >= 60" | bc -l) )); then
            echo "✅ **GOAL MET** - Minimum 60% coverage achieved" >> coverage_comment.md
          else
            echo "❌ **GOAL NOT MET** - At least 60% coverage required" >> coverage_comment.md
          fi

          echo "" >> coverage_comment.md
          echo "📈 **Details:**" >> coverage_comment.md
          echo "\`\`\`" >> coverage_comment.md
          python -m coverage report --format=text >> coverage_comment.md
          echo "\`\`\`" >> coverage_comment.md
          echo "" >> coverage_comment.md
          echo "🔗 [See full report in artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> coverage_comment.md

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report
          path: |
            api/htmlcov/
            api/coverage.json
            api/coverage_comment.md

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: api/test-results.xml

  cleanup:
    name: Stage 5 - Cleanup
    needs: [unit-tests, integration-tests]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Create environment file
        run: |
          cp .env.example .env || echo "No .env.example found, creating new .env file"
          echo "FAIL2BAN_LOG_PATH=${{ env.FAIL2BAN_LOG_PATH }}" >> .env
          echo "FAIL2BAN_LOG_PATH=${{ env.FAIL2BAN_LOG_PATH }}" >> $GITHUB_ENV

      - name: Teardown Docker
        run: docker compose down -v --remove-orphans --rmi local

  notify-github:
    name: Stage 6 - Create GitHub Issue
    needs: [cleanup, lint, build, unit-tests, integration-tests]
    runs-on: ubuntu-latest
    if: |
      "${{ needs.lint.result }}" != 'success' ||
      "$needs.build.result" != 'success' ||
      needs.integration-tests.result != 'success' ||
      needs.unit-tests.result != 'success' ||
      needs.cleanup.result != 'success'
    permissions:
      issues: write
      contents: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # 1. Compute overall pipeline status emoji/text
      - name: Compute pipeline status
        id: compute_status
        run: |
          if [ "${{ needs.lint.result }}" == "success" ]       &&
             [ "${{ needs.build.result }}" == "success" ]      &&
             [ "${{ needs.integration-tests.result }}" == "success" ] &&
             [ "${{ needs.unit-tests.result }}" == "success" ] &&
             [ "${{ needs.cleanup.result }}" == "success" ]; then
            echo "status=✅ SUCCESS" >> "$GITHUB_OUTPUT"
          else
            echo "status=❌ FAILED"  >> "$GITHUB_OUTPUT"
          fi

      # 2. Prepare the Issue body by replacing placeholders
      - name: Render Issue template
        id: render_issue
        shell: bash
        run: |
          TEMPLATE='.github/ISSUE_TEMPLATES/ci-pipeline-template.md'
          OUT='issue-body.md'

          # Export variables for replacement
          export STATUS='${{ steps.compute_status.outputs.status }}'
          export WORKFLOW='${{ github.workflow }}'
          export REF_NAME='${{ github.ref_name }}'
          export EVENT_NAME='${{ github.event_name }}'
          export SHA='${{ github.sha }}'
          export SHORT_SHA='${{ github.sha }}' ; SHORT_SHA=${SHORT_SHA:0:7} ; export SHORT_SHA
          export ACTOR='${{ github.actor }}'
          export RUN_URL='${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}'
          export REPO='${{ github.repository }}'

          # Per-stage results
          export LINT_STATUS='${{ needs.lint.result }}'
          export BUILD_STATUS='${{ needs.build.result }}'
          export INTEGRATION_STATUS='${{ needs.integration-tests.result }}'
          export UNIT_STATUS='${{ needs.unit-tests.result }}'
          export CLEANUP_STATUS='${{ needs.cleanup.result }}'

          export COVERAGE='${{ needs.unit-tests.outputs.coverage }}'
          if [ -z "$COVERAGE" ]; then
            COVERAGE="N/A"
          fi

          # Replacement using Perl (keeps newlines, handles missing vars)
          perl -pe 's/\{\{(\w+)\}\}/$ENV{$1}/ge' "$TEMPLATE" > "$OUT"

      - name: Download coverage artifact
        uses: actions/download-artifact@v4
        with:
          name: coverage-report # Artifact name from unit-tests job
          # By default, files are restored to their original paths relative to GITHUB_WORKSPACE.
          # So api/coverage_comment.md will be at $GITHUB_WORKSPACE/api/coverage_comment.md

      - name: Prepare Issue body with coverage
        run: |
          COVERAGE_COMMENT_TEXT="N/A (Coverage data not found)"
          COVERAGE_FILE_PATH="coverage_comment.md"

          if [ -f "$COVERAGE_FILE_PATH" ]; then
            if [ -s "$COVERAGE_FILE_PATH" ]; then
              COVERAGE_COMMENT_TEXT=$(cat "$COVERAGE_FILE_PATH")
            else
              echo "Warning: $COVERAGE_FILE_PATH is empty."
              COVERAGE_COMMENT_TEXT="Coverage report generated but is empty."
            fi
          else
            echo "Warning: $COVERAGE_FILE_PATH not found after attempting to download artifact. Using default text for coverage."
          fi

          export COVERAGE_COMMENT_TO_INSERT="$COVERAGE_COMMENT_TEXT"
          mv issue-body.md issue-body-temp.md
          perl -0777 -pe 's/\{\{COVERAGE_COMMENT\}\}/\Q$ENV{COVERAGE_COMMENT_TO_INSERT}\E/sg' issue-body-temp.md > issue-body-final.md

      # 4. Create (or comment-on) the Issue
      - name: Create Issue from file
        uses: peter-evans/create-issue-from-file@v5
        with:
          title: |
            CI Pipeline ${{ steps.compute_status.outputs.status }} - ${{ github.workflow }} on ${{ github.ref_name }}
          content-filepath: issue-body-final.md
          assignees: ${{ github.actor }}
          labels: |
            ci-pipeline,
            fail2ban-dashboard,
            ${{ github.ref_name }},
            ${{ github.event_name }}

  notify-jira:
    name: Stage 7 - Notify Jira
    environment: JIRA
    needs: [cleanup, lint, build, unit-tests, integration-tests]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Verify Jira variables
        env:
          JIRA_USER_EMAIL: ${{ secrets.JIRA_USER_EMAIL }}
          JIRA_API_TOKEN: ${{ secrets.JIRA_API_TOKEN }}
          JIRA_PROJECT_KEY: ${{ secrets.JIRA_PROJECT_KEY }}
          JIRA_BASE_URL: ${{ secrets.JIRA_BASE_URL }}
        run: |
          missing_vars=""
          for var in JIRA_USER_EMAIL JIRA_API_TOKEN JIRA_PROJECT_KEY JIRA_BASE_URL; do
            if [ -z "${!var}" ]; then
              missing_vars="$missing_vars $var"
            fi
          done
          if [ -n "$missing_vars" ]; then
            echo "ERROR: Missing Jira secrets:$missing_vars"
            exit 1
          fi
          echo "✅ All Jira secrets are configured"

      - name: Notify Jira with CI report
        env:
          JIRA_USER_EMAIL: ${{ secrets.JIRA_USER_EMAIL }}
          JIRA_API_TOKEN: ${{ secrets.JIRA_API_TOKEN }}
          JIRA_PROJECT_KEY: ${{ secrets.JIRA_PROJECT_KEY }}
          JIRA_BASE_URL: ${{ secrets.JIRA_BASE_URL }}
        run: |
          # Determinar el estado del pipeline
          if [[ "${{ needs.lint.result }}" == "success" && \
                "${{ needs.build.result }}" == "success" && \
                "${{ needs.integration-tests.result }}" == "success" && \
                "${{ needs.unit-tests.result }}" == "success" && \
                "${{ needs.cleanup.result }}" == "success" ]]; then
            STATUS="✅ SUCCESSFUL"
          else
            STATUS="❌ FAILED"
          fi

          # Variables para el resumen y enlaces
          SUMMARY="CI Pipeline $STATUS - ${{ github.workflow }} on ${{ github.ref_name }}"
          PIPELINE_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          COMMIT_URL="${{ github.server_url }}/${{ github.repository }}/commit/${{ github.sha }}"

          # Construir el JSON en formato ADF usando jq
          PAYLOAD=$(jq -n \
            --arg projectKey "$JIRA_PROJECT_KEY" \
            --arg summary "$SUMMARY" \
            --arg status "$STATUS" \
            --arg branch "${{ github.ref_name }}" \
            --arg event "${{ github.event_name }}" \
            --arg commit "${{ github.sha }}" \
            --arg author "${{ github.actor }}" \
            --arg commitMsg "${{ github.event.head_commit.message }}" \
            --arg lint "${{ needs.lint.result }}" \
            --arg build "${{ needs.build.result }}" \
            --arg integration "${{ needs.integration-tests.result }}" \
            --arg unit "${{ needs.unit-tests.result }}" \
            --arg cleanup "${{ needs.cleanup.result }}" \
            --arg pipelineUrl "$PIPELINE_URL" \
            --arg commitUrl "$COMMIT_URL" \
            '{
              fields: {
                project: { key: $projectKey },
                summary: $summary,
                description: {
                  type: "doc",
                  version: 1,
                  content: [
                    {
                      type: "heading",
                      attrs: { level: 2 },
                      content: [{ type: "text", text: "Pipeline Summary" }]
                    },
                    {
                      type: "paragraph",
                      content: [{ type: "text", text: ("Status: " + $status) }]
                    },
                    {
                      type: "paragraph",
                      content: [{ type: "text", text: ("Branch: " + $branch) }]
                    },
                    {
                      type: "paragraph",
                      content: [{ type: "text", text: ("Event: " + $event) }]
                    },
                    {
                      type: "paragraph",
                      content: [{ type: "text", text: ("Commit: " + $commit) }]
                    },
                    {
                      type: "paragraph",
                      content: [{ type: "text", text: ("Author: " + $author) }]
                    },
                    {
                      type: "paragraph",
                      content: [{ type: "text", text: ("Commit message: " + $commitMsg) }]
                    },
                    {
                      type: "heading",
                      attrs: { level: 3 },
                      content: [{ type: "text", text: "Pipeline Stages" }]
                    },
                    {
                      type: "paragraph",
                      content: [{ type: "text", text: ((if $lint == "success" then "✅" else "❌" end) + " Stage 1 - Code Quality Check (Lint)") }]
                    },
                    {
                      type: "paragraph",
                      content: [{ type: "text", text: ((if $build == "success" then "✅" else "❌" end) + " Stage 2 - Container Build") }]
                    },
                    {
                      type: "paragraph",
                      content: [{ type: "text", text: ((if $integration == "success" then "✅" else "❌" end) + " Stage 3 - Integration & Flow Test") }]
                    },
                    {
                      type: "paragraph",
                      content: [{ type: "text", text: ((if $unit == "success" then "✅" else "❌" end) + " Stage 4 - Unit Tests") }]
                    },
                    {
                      type: "paragraph",
                      content: [{ type: "text", text: ((if $cleanup == "success" then "✅" else "❌" end) + " Stage 5 - Cleanup") }]
                    },
                    {
                      type: "heading",
                      attrs: { level: 3 },
                      content: [{ type: "text", text: "Links" }]
                    },
                    {
                      type: "paragraph",
                      content: [
                        { type: "text", text: "View pipeline: " },
                        {
                          type: "text",
                          text: $pipelineUrl,
                          marks: [{
                            type: "link",
                            attrs: { href: $pipelineUrl }
                          }]
                        }
                      ]
                    },
                    {
                      type: "paragraph",
                      content: [
                        { type: "text", text: "View commit: " },
                        {
                          type: "text",
                          text: $commitUrl,
                          marks: [{
                            type: "link",
                            attrs: { href: $commitUrl }
                          }]
                        }
                      ]
                    }
                  ]
                },
                issuetype: { name: "Task" },
                labels: [
                  "ci-pipeline",
                  "fail2ban-dashboard",
                  $branch,
                  $event
                ]
              }
            }'
          )

          # Enviar a Jira
          curl -X POST -u "$JIRA_USER_EMAIL:$JIRA_API_TOKEN" \
            -H "Content-Type: application/json" \
            --data "$PAYLOAD" \
            "$JIRA_BASE_URL/rest/api/3/issue"
